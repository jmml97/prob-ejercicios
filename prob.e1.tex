% archivo:    prob.e1.tex
% asignatura: Probabilidad
% autores:      José María Martín Luque, José Luis Ruiz Benito, Ricardo Ruiz Fernández de Alba
\documentclass[
  a4paper,
  spanish,
  12pt,
]{scrartcl}

\linespread{1.1}


%-------------------------------------------------------------------------------
%	PAQUETES
%-------------------------------------------------------------------------------

% Idioma

\usepackage[es-noindentfirst, es-tabla]{babel}

% Citas de texto en línea/bloque

\usepackage[autostyle]{csquotes}

% Matemáticas

\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}
\usepackage{commath}
\usepackage{xfrac}

% Fuentes personalizadas para utilizar con XeLaTeX o LuaLaTeX

\usepackage[no-math]{fontspec}
\setmainfont{Libertinus Serif}
\setsansfont{Libertinus Sans}
\setmonofont{Libertinus Mono}

\usepackage[math-style=TeX]{unicode-math}
\setmathfont{Libertinus Math}


% Configuración de microtype

\defaultfontfeatures{Ligatures=TeX,Numbers=Lining}
\usepackage[activate={true,nocompatibility},final,tracking=true,factor=1100,stretch=10,shrink=10]{microtype}
\SetTracking{encoding={*}, shape=sc}{0}

% Enlaces y colores

\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
  colorlinks=true,
  citecolor=,
  linkcolor=,
  urlcolor=blue,
}

% Otros elementos de página

\usepackage{enumitem}
%\setlist[itemize]{leftmargin=*}
%\setlist[enumerate]{leftmargin=*}

\usepackage[labelfont=sc]{caption}

\usepackage{booktabs}
\renewcommand\arraystretch{1.5}

% Tikz

\usepackage{tikz}
\usetikzlibrary{babel}
\usepackage{float}

% Código

\usepackage{listings}
\lstset{
	basicstyle=\ttfamily,%
	breaklines=true,%
	captionpos=b,                    % sets the caption-position to bottom
  tabsize=2,	                   % sets default tabsize to 2 spaces
  frame=lines,
  numbers=left,
  stepnumber=1,
  aboveskip=12pt,
  showstringspaces=false,
  keywordstyle=\bfseries,
  commentstyle=\itshape,
  columns=flexible,
}
%\renewcommand{\lstlistingname}{Listado}

% ENTORNOS

\newtheoremstyle{ejercicio-style}  % Nombre del estilo
{2\topsep}                                  % Espacio por encima
{1.5\topsep}                                  % Espacio por debajo
{\itshape}                                  % Fuente del cuerpo
{0pt}                                  % Identación
{\scshape}                      % Fuente para la cabecera
{.}                                 % Puntuación tras la cabecera
{5pt plus 1pt minus 1pt}                              % Espacio tras la cabecera
{{\thmname{#1}\thmnumber{ #2}}\thmnote{ (#3)}}  % Especificación de la cabecera

\newtheoremstyle{remark-style}
{-\topsep}                                  % Espacio por encima
{2\topsep}                                  % Espacio por debajo
{}                                  % Fuente del cuerpo
{0pt}                                  % Identación
{\itshape}
{.}
{5pt plus 1pt minus 1pt}                              % Espacio tras la cabecera
{}

% Ejercicios y solución
\theoremstyle{ejercicio-style}
\newtheorem{ejer}{Ejercicio}

\theoremstyle{remark-style}
\newtheorem*{sol}{Solución}


% Márgenes
\usepackage[bottom=3.125cm, top=2.5cm, left=3.5cm, right=3.5cm, marginparwidth=70pt]{geometry}

\usepackage{hyphenat}

%-------------------------------------------------------------------------------
%	CONTENIDO
%-------------------------------------------------------------------------------

\begin{document}

\begin{flushright}
  José María Martín Luque
  
  José Luis Ruiz Benito

  Ricardo Ruiz Fernández de Alba
  \vspace{.5em}

  \textit{Probabilidad}

  D.\,G. en Ing. Informática y Matemáticas

  \textsc{Universidad de Granada}\vspace{.5em}

  \today\vspace{.5em}
\end{flushright}

\begin{flushleft}
  \scshape\Large Entrega 1. Propiedades de la esperanza. Desigualdad de Cauchy-Schwarz.
\end{flushleft}

\begin{ejer}
  Demuestra las siguientes propiedades de la esperanza matemática de vectores aleatorios: \begin{enumerate}
    \item Linealidad. Sea \(\symbf{X} = (X_1, \dots, X_n)\) un vector aleatorio tal que existe \(\operatorname{E}[X_i]\) para todo \(i = 1, \dots, n\) y para cualesquiera \((a_1, \dots, a_n), (b_1, \dots, b_n) \in \mathbb R^n\) existe además \(\operatorname{E}[a_iX_i + b_i]\) para todo \(i = 1, \dots, n\). 
    Entonces se tiene que \[
      \exists \operatorname{E}\left[\sum_{i=1}^n a_iX_i + b_i\right] =  \sum_{i=1}^{n}a_i \operatorname{E}[X_i] + b_i\,.
    \]
    \item Conservación del orden. Sean \(X_1\) y \(X_2\) dos variables aleatorias tales que \(X_1 \leq X_2\) y existen tanto \(\operatorname{E}[X_1]\) como \(\operatorname{E}[X_2]\). 
    Entonces se verifica que \(\operatorname{E}[X_1] \leq \operatorname{E}[X_2]\).
  \end{enumerate}
\end{ejer}

\begin{sol}
  Veamos la solución por apartados. \begin{enumerate}
    \item Vemos primero el caso continuo, pues el caso discreto será análogo. 
    Comenzamos probando la existencia. 
    Que exista \(\operatorname{E}\left[\sum_{i=1}^n a_iX_i + b_i\right]\) equivale a que \[
      \int_{\mathbb R^n}\left|\sum_{i=1}^n a_ix_i + b_i\right| f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n < \infty.
    \] 
    Aplicando la desigualdad triangular llegamos a que \begin{align*}
      \int_{\mathbb R^n}&\left|\sum_{i=1}^n a_ix_i + b_i\right| f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n\\
        &\leq \int_{\mathbb R^n}\left(\sum_{i=1}^n \left|a_ix_i + b_i\right|\right) f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n\\
        \intertext{y como la integral de la suma es la suma de las integrales,}
        &= \sum_{i=1}^n\int_{\mathbb R^n}\left|a_ix_i + b_i\right| f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n\\
        &= \sum_{i=1}^n \operatorname{E}[a_iX_i + b_i]\\
        &< \infty,
    \end{align*} puesto que al existir dichas esperanzas por hipótesis, tenemos una suma de términos finitos.

    Ahora, para ver que se da dicha igualdad observamos que \begin{align*}
      \operatorname{E}&\left[\sum_{i=1}^n a_iX_i + b_i\right] \\
        &= \int_{\mathbb R^n}\sum_{i=1}^n (a_ix_i + b_i) f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n\\
        &= \sum_{i=1}^n\left(\int_{\mathbb R^n} (a_ix_i + b_i) f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n\right)\\
        &= \sum_{i=1}^n\left(\int_{\mathbb R^n} a_ix_if_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n + \int_{\mathbb R^n} b_if_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n\right)\\
        &= \sum_{i=1}^n\left(a_i\int_{\mathbb R^n}x_if_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n + b_i\int_{\mathbb R^n} f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n\right),
    \end{align*} donde la integral que multiplica a cada \(a_i\) es \(\operatorname{E}[X_i]\), y la que multiplica a \(b_i\), la integral de la función de densidad ---cuyo valor es \(1\) por definición---. 
    En consecuencia, tenemos que \[
      \operatorname{E}\left[\sum_{i=1}^n a_iX_i + b_i\right] = \sum_{i=1}^n\left(a_i \operatorname{E}[X_i] + b_i\right),
    \] como queríamos.

    En el caso discreto ---\(P(\symbf X \in E_{\symbf X})  =  1\), siendo \(E_{\symbf X} \subset \mathbb R\) numerable---, que exista la esperanza \(\operatorname{E}\left[\sum_{i=1}^n a_iX_i + b_i\right]\) equivale a que \[
      \sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}}\left|\sum_{i=1}^n a_ix_i + b_i\right| f_X(x_1, \dots, x_n)\dif x_1\dots\dif x_n < \infty.
    \] 
    Aplicando la desigualdad triangular llegamos a que \begin{align*}
      \sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}}&\left|\sum_{i=1}^n a_ix_i + b_i\right| p_X(x_1, \dots, x_n)\\
        &\leq \sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}}\left(\sum_{i=1}^n \left|a_ix_i + b_i\right| p_X(x_1, \dots, x_n)\right)\\
        &= \sum_{i=1}^n\left(\sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}}\left|a_ix_i + b_i\right| p_X(x_1, \dots, x_n)\right)\\
        &= \sum_{i=1}^n \operatorname{E}[a_iX_i + b_i]\\
        &< \infty,
    \end{align*} puesto que al existir dichas esperanzas por hipótesis, tenemos una suma de términos finitos.

    Ahora, para ver que se da dicha igualdad observamos que \begin{align*}
      \operatorname{E}&\left[\sum_{i=1}^n a_iX_i + b_i\right] \\
        &= \sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}}\left(\sum_{i=1}^n (a_ix_i + b_i) p_X(x_1, \dots, x_n)\right)\\
        &= \sum_{i=1}^n\left(\sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}} (a_ix_i + b_i) p_X(x_1, \dots, x_n)\right)\\
        &= \sum_{i=1}^n\left(\sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}} a_ix_ip_X(x_1, \dots, x_n) + \sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}} b_ip_X(x_1, \dots, x_n)\right)\\
        &= \sum_{i=1}^n\left(a_i\sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}}x_ip_X(x_1, \dots, x_n) + b_i\sum_{(x_1, \dots,\, x_n) \in E_{\symbf X}} p_X(x_1, \dots, x_n)\right),
    \end{align*} donde la suma que multiplica a cada \(a_i\) es \(\operatorname{E}[X_i]\), y la que multiplica a \(b_i\), la suma de los valores de la función masa de probabilidad ---cuyo valor es \(1\) por definición---. 
    En consecuencia, tenemos que \[
      \operatorname{E}\left[\sum_{i=1}^n a_iX_i + b_i\right] = \sum_{i=1}^n\left(a_i \operatorname{E}[X_i] + b_i\right),
    \] como queríamos.
  
    \item
      \begin{enumerate}
        \item Caso continuo: Suponemos que \(\symbf{X} = (X_1, X_2)\) es un vector aleatorio continuo y \(f_X(x_1, x_2)\) su función de densidad. 
        Utilizando que \(X_1 \leq X_2\) y que si \(x_1 > x_2\) se tiene que \(f_X(x_1, x_2) = 0\), y calculando las respectivas esperanzas, llegamos a al resultado que buscamos
          \begin{align*}
            \operatorname{E}[X_1] &= \int_{\left\{(x_1, x_2) : x_1 \leq x_2\right\}} x_1 f_X (x_1, x_2) \dif x_1 \dif x_2 \\
              &\leq \int_{\left\{(x_1, x_2) : x_1 \leq x_2\right\}} x_2 f_X (x_1, x_2) \dif x_1 \dif x_2 = \operatorname{E}[X_2].
          \end{align*}
          
        \item Caso discreto: Suponemos que \(\symbf{X} = (X_1, X_2)\) es un vector aleatorio discreto y \(p_X(x_1, x_2)\) su función masa de probabilidad. De nuevo, utilizando que \(X_1 \leq X_2\) y que si \(x_1 > x_2\) se tiene que \(p_X(x_1, x_2) = 0\), y calculando las respectivas esperanzas, llegamos a al resultado que buscamos
          \begin{align*}
            \operatorname{E}[X_1] &= \sum_{\left\{(x_1, x_2) : x_1 \leq x_2\right\}} x_1 f_X (x_1, x_2) \\
              &\leq \sum_{\left\{(x_1, x_2) : x_1 \leq x_2\right\}} x_2 f_X (x_1, x_2) = \operatorname{E}[X_2].
          \end{align*}
      \end{enumerate}
  \end{enumerate}
\end{sol}

\newpage

\begin{ejer}
  Demuestra la desigualdad de Cauchy-Schwarz: \begin{displayquote}
    Sean \(X\), \(Y\) variables aleatorias tales que existen las esperanzas \(\operatorname{E}[X^2]\) y \(\operatorname{E}[Y^2]\). Entonces:
    \begin{enumerate}
      \item \(\left(\operatorname{E}[XY]\right)^2 \leq \operatorname{E}[X^2] \operatorname{E}[Y^2]\).
      \item Si \(X\) o \(Y\) es degenerada en cero o las dos son degeneradas, se da la igualdad.
      \item Si \(X\) e \(Y\) son no degeneradas, se da la igualdad si y sólo si existen \(a,b \in \mathbb{R}\setminus\{0\}\) tales que \(\operatorname{P}[aX+bY=0] = 1\).
    \end{enumerate}
  \end{displayquote}
\end{ejer}

\begin{sol}
  Veamos la solución por apartados: \begin{enumerate}
    \item Sabemos por las propiedades de los momentos de segundo orden que si existen \(\operatorname{E}[X^2]\) y \(\operatorname{E}[Y^2]\) entonces existe \(\operatorname{E}[XY]\). 
    Analizamos de forma separada los casos \(\operatorname{E}[X^2] = 0\) y \(\operatorname{E}[X^2] \neq 0\).
  	  \begin{itemize}
        \item Si \(\operatorname E[X^2] = 0\), como \(X^2 > 0\), debe cumplirse que \(\operatorname{P}[X=0] = 1\) y \(\operatorname{P}[X=0] = 1\), luego \(\operatorname{E}[XY]=0\). 
        Por tanto se cumple la igualdad cuando cuando \(\operatorname{E}[X^2] = 0\) o bien \(\operatorname{E}[Y^2] = 0\) y con ello demostramos además la segunda afirmación.
  	    
  	    \item Veamos ahora el caso en el que \(\operatorname E[X^2] \neq 0\). 
  	      Definimos el valor \[\alpha_0 = -\frac{\operatorname{E}[XY]}{\operatorname{E}[X^2]} \in \mathbb{R}\] y la variable aleatoria \(Z=\alpha_0 X + Y\).
  	      Calculamos la esperanza de \(Z^2\):
  	      \begin{align*}
  	        \operatorname{E}[Z^2] &= \operatorname{E}\left[(\alpha_0 X + Y)^2\right] \\
  	        &= \operatorname{E}[\alpha_0^2 X^2 + Y^2 + 2\alpha_0 X Y] \\ 
  	        &= \alpha_0^2 \operatorname{E}[X^2] + \operatorname{E}[Y^2] + 2 \alpha_0 \operatorname{E}[XY] \\
  	        &= \frac{\left(\operatorname{E}[XY]\right)^2}{\left(\operatorname{E}[X^2]\right)^2} \operatorname{E}[X^2] + \operatorname{E}[Y^2] - 2\frac{\operatorname{E}[XY]}{\operatorname{E}[X^2]} \operatorname{E}[XY] \\
  	        &= \frac{\left(\operatorname{E}[XY]\right)^2}{\operatorname{E}[X^2]} + \operatorname{E}[Y^2] - 2\frac{\left(\operatorname{E}[XY]\right)^2}{\operatorname{E}[X^2]} \\
  	        &= \operatorname{E}[Y^2] - \frac{\left(\operatorname{E}[XY]\right)^2}{\operatorname{E}[X^2]}\,.
  	      \end{align*}
  	      Como \(\operatorname{E}[Z^2] \geq 0\), tenemos que \[\operatorname{E}[Y^2] - \frac{\left(\operatorname{E}[XY]\right)^2}{\operatorname{E}[X^2]} \geq 0\] si y solo si \(\left(\operatorname{E}[XY]\right)^2 \leq \operatorname{E}[X^2] \operatorname{E}[Y^2]\), luego \(\operatorname{E}[XY] \leq \operatorname{E}[X^2] \operatorname{E}[Y^2]\), que es la desigualdad buscada.
  	  \end{itemize}
  	
  	\item Ya demostrado en el apartado anterior.
  	
  	\item Puesto que ninguna de las variables es degenerada se tiene que \(\operatorname{E}[X^2] \neq 0\) y que \(\operatorname{E}[Y^2] \neq 0\). Veamos ambas implicaciones por separado.
  
    \(\boxed{\implies}\) \ Definimos de nuevo el valor \[
      \alpha_0 = -\frac{\operatorname{E}[XY]}{\operatorname{E}[X^2]} \in \mathbb{R}
    \] y recordamos que \[
      \operatorname{E}\left[(\alpha_0 X + Y)^2\right] = \operatorname{E}[Y^2] - \frac{\left(\operatorname{E}[XY]\right)^2}{\operatorname{E}[X^2]}\,.
    \] 
    Si se verifica la igualdad, entonces \[
      \operatorname{E}[Y^2] - \frac{\left(\operatorname{E}[XY]\right)^2}{\operatorname{E}[X^2]} = 0
    \] y se tiene que \(\operatorname{E}\left[(\alpha_0 X + Y)^2\right] = 0\). 
    Como \((\alpha_0 X + Y)^2 \geq 0\), debe ser \(\operatorname{P}[\alpha_0 X + Y = 0] = 1\). 
    Por tanto, \(a = \alpha_0\) y \(b=1\).

    Falta comprobar que \(a = \alpha_0 \neq 0\) o, equivalentemente, que \(\operatorname{E}[XY] \neq 0\), para lo que procedemos por reducción al absurdo. 
    Supongamos que \(\operatorname{E}[XY] = 0\). 
    Entonces se tiene que \(\operatorname{E}[X^2] = 0\) o bien \(\operatorname{E}[Y^2] = 0\), lo cual es imposible por hipótesis.

    \(\boxed{\impliedby}\) Partimos de que existen \(a, b \in \mathbb R\) tales que \(\operatorname{P}[aX + bY = 0] = 1\), lo que equivale a que \(\operatorname{P}\left[Y = \sfrac{-a}{b}\,X\right] = 1\). 
    Esto implica que \[
      \operatorname{E}[Y^2] = \frac{a^2}{b^2}\operatorname{E}[X^2] \quad \text{y que} \quad \operatorname{E}[XY] = -\frac{a}{b}\operatorname{E}[X^2],
    \] lo que se da si y solo si \[
      \left(\operatorname{E}[XY]\right)^2 = \operatorname{E}[X^2] \operatorname{E}[Y^2].
    \]
  	
  \end{enumerate}
\end{sol}

\end{document}
